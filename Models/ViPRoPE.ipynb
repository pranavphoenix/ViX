{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch, math\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\n!pip install torchsummary\nfrom torchsummary import summary\nimport time\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import TransformerEncoder, TransformerEncoderLayer\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nimport torch.optim as optim\n!pip install torchsummary\nfrom torchsummary import summary\n!pip install einops\nfrom math import ceil\n# !pip install nystrom-attention\n!pip install performer_pytorch\n\nfrom torch import nn, einsum\nfrom einops import rearrange, repeat\nfrom einops.layers.torch import Rearrange\n\nfrom einops import rearrange, reduce\n\n# helpers\nfrom einops import reduce\n\ntransform = transforms.Compose(\n        [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\nbatch_size = 192\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                          shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n                                         shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\ndef accuracy(output, target, topk=(1,5)):\n    \"\"\"Computes the precision@k for the specified values of k\n    prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n    \"\"\"\n    maxk = max(topk)\n         # sizefunction: the number of total elements\n    batch_size = target.size(0) \n \n         # topk function selects the number of k before output\n    _, pred = output.topk(maxk, 1, True, True)\n         ##########Do not understand t()k\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))   \n    res = []\n    for k in topk:\n        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"shXYo9eIX8JQ","outputId":"c37a94b5-38bd-43a2-90a2-10ca0837f780","execution":{"iopub.status.busy":"2021-07-29T03:50:46.765216Z","iopub.execute_input":"2021-07-29T03:50:46.765602Z","iopub.status.idle":"2021-07-29T03:51:27.122227Z","shell.execute_reply.started":"2021-07-29T03:50:46.765504Z","shell.execute_reply":"2021-07-29T03:51:27.121283Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nRequirement already satisfied: torchsummary in /opt/conda/lib/python3.7/site-packages (1.5.1)\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting einops\n  Downloading einops-0.3.0-py2.py3-none-any.whl (25 kB)\nInstalling collected packages: einops\nSuccessfully installed einops-0.3.0\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting performer_pytorch\n  Downloading performer_pytorch-1.0.11-py3-none-any.whl (12 kB)\nRequirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.7/site-packages (from performer_pytorch) (1.7.0)\nCollecting axial-positional-embedding>=0.1.0\n  Downloading axial_positional_embedding-0.2.1.tar.gz (2.6 kB)\nRequirement already satisfied: einops>=0.3 in /opt/conda/lib/python3.7/site-packages (from performer_pytorch) (0.3.0)\nCollecting local-attention>=1.1.1\n  Downloading local_attention-1.4.3-py3-none-any.whl (5.0 kB)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.6->performer_pytorch) (0.18.2)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.6->performer_pytorch) (3.7.4.3)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.6->performer_pytorch) (0.6)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.6->performer_pytorch) (1.19.5)\nBuilding wheels for collected packages: axial-positional-embedding\n  Building wheel for axial-positional-embedding (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for axial-positional-embedding: filename=axial_positional_embedding-0.2.1-py3-none-any.whl size=2902 sha256=41e4bf22a0121c1d241c83c167a5aec9e7f35cdb9fc3c5ddaeb346a1572fb26e\n  Stored in directory: /root/.cache/pip/wheels/4a/2c/c3/9a1cb267c0d0d9b6eeba7952addb32b17857d1f799690c27a8\nSuccessfully built axial-positional-embedding\nInstalling collected packages: local-attention, axial-positional-embedding, performer-pytorch\nSuccessfully installed axial-positional-embedding-0.2.1 local-attention-1.4.3 performer-pytorch-1.0.11\n\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\nDownloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31c2e642f39545bba6f1326479321e45"}},"metadata":{}},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.cuda.amp import autocast\nfrom functools import partial\nfrom contextlib import contextmanager\nfrom local_attention import LocalAttention\nfrom axial_positional_embedding import AxialPositionalEmbedding\nfrom performer_pytorch.reversible import ReversibleSequence, SequentialSequence\n\ndef exists(val):\n    return val is not None\n\ndef empty(tensor):\n    return tensor.numel() == 0\n\ndef default(val, d):\n    return val if exists(val) else d\n\n@contextmanager\ndef null_context():\n    yield\n\ndef rotate_every_two(x):\n    x = rearrange(x, '... (d j) -> ... d j', j = 2)\n    x1, x2 = x.unbind(dim = -1)\n    x = torch.stack((-x2, x1), dim = -1)\n    return rearrange(x, '... d j -> ... (d j)')\n\ndef apply_rotary_pos_emb(q, k, sinu_pos):\n    sinu_pos = rearrange(sinu_pos, '() n (j d) -> n j d', j = 2)\n    sin, cos = sinu_pos.unbind(dim = -2)\n\n    sin, cos = map(lambda t: repeat(t, 'b n -> b (n j)', j = 2), (sin, cos))\n    q, k = map(lambda t: (t * cos) + (rotate_every_two(t) * sin), (q, k))\n    return q, k\n\nclass FixedPositionalEmbedding(nn.Module):\n    def __init__(self, dim, max_seq_len):\n        super().__init__()\n        inv_freq = 1. / (10000 ** (torch.arange(0, dim, 2).float() / dim))\n        position = torch.arange(0, max_seq_len, dtype=torch.float)\n        sinusoid_inp = torch.einsum(\"i,j->ij\", position, inv_freq)\n        emb = torch.cat((sinusoid_inp.sin(), sinusoid_inp.cos()), dim=-1)\n        self.register_buffer('emb', emb)\n\n    def forward(self, x):\n        return self.emb[None, :x.shape[1], :].to(x)\n# def cast_tuple(val):\n#     return (val,) if not isinstance(val, tuple) else val\n\ndef get_module_device(module):\n    return next(module.parameters()).device\n\ndef find_modules(nn_module, type):\n    return [module for module in nn_module.modules() if isinstance(module, type)]\n\nclass Always(nn.Module):\n    def __init__(self, val):\n        super().__init__()\n        self.val = val\n\n    def forward(self, *args, **kwargs):\n        return self.val\n\n# kernel functions\n\n# transcribed from jax to pytorch from\n# https://github.com/google-research/google-research/blob/master/performer/fast_attention/jax/fast_attention.py\n\ndef softmax_kernel(data, *, projection_matrix, is_query, normalize_data=True, eps=1e-4, device = None):\n    b, h, *_ = data.shape\n\n    data_normalizer = (data.shape[-1] ** -0.25) if normalize_data else 1.\n\n    ratio = (projection_matrix.shape[0] ** -0.5)\n\n    projection = repeat(projection_matrix, 'j d -> b h j d', b = b, h = h)\n    projection = projection.type_as(data)\n\n    data_dash = torch.einsum('...id,...jd->...ij', (data_normalizer * data), projection)\n\n    diag_data = data ** 2\n    diag_data = torch.sum(diag_data, dim=-1)\n    diag_data = (diag_data / 2.0) * (data_normalizer ** 2)\n    diag_data = diag_data.unsqueeze(dim=-1)\n\n    if is_query:\n        data_dash = ratio * (\n            torch.exp(data_dash - diag_data -\n                    torch.max(data_dash, dim=-1, keepdim=True).values) + eps)\n    else:\n        data_dash = ratio * (\n            torch.exp(data_dash - diag_data - torch.max(data_dash)) + eps)\n\n    return data_dash.type_as(data)\n\ndef generalized_kernel(data, *, projection_matrix, kernel_fn = nn.ReLU(), kernel_epsilon = 0.001, normalize_data = True, device = None):\n    b, h, *_ = data.shape\n\n    data_normalizer = (data.shape[-1] ** -0.25) if normalize_data else 1.\n\n    if projection_matrix is None:\n        return kernel_fn(data_normalizer * data) + kernel_epsilon\n\n    projection = repeat(projection_matrix, 'j d -> b h j d', b = b, h = h)\n    projection = projection.type_as(data)\n\n    data_dash = torch.einsum('...id,...jd->...ij', (data_normalizer * data), projection)\n\n    data_prime = kernel_fn(data_dash) + kernel_epsilon\n    return data_prime.type_as(data)\n\ndef orthogonal_matrix_chunk(cols, device = None):\n    unstructured_block = torch.randn((cols, cols), device = device)\n    q, r = torch.qr(unstructured_block.cpu(), some = True)\n    q, r = map(lambda t: t.to(device), (q, r))\n    return q.t()\n\ndef gaussian_orthogonal_random_matrix(nb_rows, nb_columns, scaling = 0, device = None):\n    nb_full_blocks = int(nb_rows / nb_columns)\n\n    block_list = []\n\n    for _ in range(nb_full_blocks):\n        q = orthogonal_matrix_chunk(nb_columns, device = device)\n        block_list.append(q)\n\n    remaining_rows = nb_rows - nb_full_blocks * nb_columns\n    if remaining_rows > 0:\n        q = orthogonal_matrix_chunk(nb_columns, device = device)\n        block_list.append(q[:remaining_rows])\n\n    final_matrix = torch.cat(block_list)\n\n    if scaling == 0:\n        multiplier = torch.randn((nb_rows, nb_columns), device = device).norm(dim = 1)\n    elif scaling == 1:\n        multiplier = math.sqrt((float(nb_columns))) * torch.ones((nb_rows,), device = device)\n    else:\n        raise ValueError(f'Invalid scaling {scaling}')\n\n    return torch.diag(multiplier) @ final_matrix\n\n# linear attention classes with softmax kernel\n\n# non-causal linear attention\ndef linear_attention(q, k, v):\n    k_cumsum = k.sum(dim = -2)\n    D_inv = 1. / torch.einsum('...nd,...d->...n', q, k_cumsum.type_as(q))\n    context = torch.einsum('...nd,...ne->...de', k, v)\n    out = torch.einsum('...de,...nd,...n->...ne', context, q, D_inv)\n#     print(\"linear attention\", out.size)\n    return out\n\nclass FastAttention(nn.Module):\n    def __init__(self, dim_heads, nb_features = None, ortho_scaling = 0, causal = False, generalized_attention = False, kernel_fn = nn.ReLU(), no_projection = False):\n        super().__init__()\n        nb_features = default(nb_features, int(dim_heads * math.log(dim_heads)))\n\n        self.dim_heads = dim_heads\n        self.nb_features = nb_features\n        self.ortho_scaling = ortho_scaling\n\n        self.create_projection = partial(gaussian_orthogonal_random_matrix, nb_rows = self.nb_features, nb_columns = dim_heads, scaling = ortho_scaling)\n        projection_matrix = self.create_projection()\n        self.register_buffer('projection_matrix', projection_matrix)\n\n        self.generalized_attention = generalized_attention\n        self.kernel_fn = kernel_fn\n\n        # if this is turned on, no projection will be used\n        # queries and keys will be softmax-ed as in the original efficient attention paper\n        self.no_projection = no_projection\n\n        self.causal = causal\n        \n    @torch.no_grad()\n    def redraw_projection_matrix(self, device):\n        projections = self.create_projection(device = device)\n        self.projection_matrix.copy_(projections)\n        del projections\n\n    def forward(self, q, k, v):\n        device = q.device\n        \n        if self.no_projection:\n            q = q.softmax(dim = -1)\n            k = torch.exp(k) if self.causal else k.softmax(dim = -2)\n\n        elif self.generalized_attention:\n            create_kernel = partial(generalized_kernel, kernel_fn = self.kernel_fn, projection_matrix = self.projection_matrix, device = device)\n            q, k = map(create_kernel, (q, k))\n\n        else:\n            create_kernel = partial(softmax_kernel, projection_matrix = self.projection_matrix, device = device)\n            q = create_kernel(q, is_query = True)\n            k = create_kernel(k, is_query = False)\n\n        attn_fn = linear_attention if not self.causal else self.causal_linear_fn\n        out = attn_fn(q, k, v)\n#         print('fastattention', out.size())\n        return out\n\n# a module for keeping track of when to update the projections\n\nclass ProjectionUpdater(nn.Module):\n    def __init__(self, instance, feature_redraw_interval):\n        super().__init__()\n        self.instance = instance\n        self.feature_redraw_interval = feature_redraw_interval\n        self.register_buffer('calls_since_last_redraw', torch.tensor(0))\n\n    def fix_projections_(self):\n        self.feature_redraw_interval = None\n\n    def redraw_projections(self):\n        model = self.instance\n\n        if not self.training:\n            return\n\n        if exists(self.feature_redraw_interval) and self.calls_since_last_redraw >= self.feature_redraw_interval:\n            device = get_module_device(model)\n\n            fast_attentions = find_modules(model, FastAttention)\n            for fast_attention in fast_attentions:\n                fast_attention.redraw_projection_matrix(device)\n\n            self.calls_since_last_redraw.zero_()\n            return\n\n        self.calls_since_last_redraw += 1\n\n    def forward(self, x):\n        raise NotImplemented\n\n# classes\n\nclass Attention(nn.Module):\n    def __init__(\n        self,\n        dim,\n        causal = False,\n        heads = 4,\n        dim_head = 32,\n        local_heads = 0,\n        local_window_size = 256,\n        nb_features = None,\n        feature_redraw_interval = 1000,\n        generalized_attention = False,\n        kernel_fn = nn.ReLU(),\n        dropout = 0.,\n        no_projection = False,\n        qkv_bias = False,\n        attn_out_bias = True\n    ):\n        super().__init__()\n        assert dim % heads == 0, 'dimension must be divisible by number of heads'\n        dim_head = default(dim_head, dim // heads)\n        inner_dim = dim_head * heads\n        self.fast_attention = FastAttention(dim_head, nb_features, causal = causal, generalized_attention = generalized_attention, kernel_fn = kernel_fn, no_projection = no_projection)\n\n        self.heads = heads\n        self.global_heads = heads - local_heads\n        self.local_attn = LocalAttention(window_size = local_window_size, causal = causal, autopad = True, dropout = dropout, look_forward = int(not causal), rel_pos_emb_config = (dim_head, local_heads)) if local_heads > 0 else None\n\n        self.to_q = nn.Linear(dim, inner_dim, bias = qkv_bias)\n        self.to_k = nn.Linear(dim, inner_dim, bias = qkv_bias)\n        self.to_v = nn.Linear(dim, inner_dim, bias = qkv_bias)\n        self.to_out = nn.Linear(inner_dim, dim, bias = attn_out_bias)\n        self.dropout = nn.Dropout(dropout)\n        \n\n    def forward(self, x, pos_emb = None, context = None, mask = None, context_mask = None, **kwargs):\n        \n        b, n, _, h, gh = *x.shape, self.heads, self.global_heads\n\n        cross_attend = exists(context)\n\n        context = default(context, x)\n        context_mask = default(context_mask, mask) if not cross_attend else context_mask\n\n        q, k, v = self.to_q(x), self.to_k(context), self.to_v(context)\n\n        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), (q, k, v))\n        (q, lq), (k, lk), (v, lv) = map(lambda t: (t[:, :gh], t[:, gh:]), (q, k, v))\n\n        attn_outs = []\n\n        if not empty(q):\n            if exists(context_mask):\n                global_mask = context_mask[:, None, :, None]\n                v.masked_fill_(~global_mask, 0.)\n\n            if exists(pos_emb) and not cross_attend:\n                q, k = apply_rotary_pos_emb(q, k, pos_emb)\n                \n\n            out = self.fast_attention(q, k, v)\n            attn_outs.append(out)\n\n\n        if not empty(lq):\n            assert not cross_attend, 'local attention is not compatible with cross attention'\n            out = self.local_attn(lq, lk, lv, input_mask = mask)\n            attn_outs.append(out)\n\n        out = torch.cat(attn_outs, dim = 1)\n        out = rearrange(out, 'b h n d -> b n (h d)')\n#         print(\"Attention\", out.size())\n        out =  self.to_out(out)\n        out = self.dropout(out)\n        return out\n\n\nclass SelfAttention(Attention):\n    def forward(self, *args, pos_emb, context = None, **kwargs):\n        assert not exists(context), 'self attention should not receive context'\n#         print(1, \"self attention module\")\n        return super().forward(*args, pos_emb, **kwargs)","metadata":{"id":"BAzGZ70mX8JZ","execution":{"iopub.status.busy":"2021-07-29T03:51:27.124030Z","iopub.execute_input":"2021-07-29T03:51:27.124649Z","iopub.status.idle":"2021-07-29T03:51:27.183920Z","shell.execute_reply.started":"2021-07-29T03:51:27.124612Z","shell.execute_reply":"2021-07-29T03:51:27.182987Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn, einsum\nimport torch.nn.functional as F\n\nfrom einops import rearrange, repeat\nfrom einops.layers.torch import Rearrange\n\n# helpers\n\ndef pair(t):\n    return t if isinstance(t, tuple) else (t, t)\n\n# classes\n\nclass PreNorm(nn.Module):\n    def __init__(self, dim, fn):\n        super().__init__()\n        self.norm = nn.LayerNorm(dim)\n        self.fn = fn\n    def forward(self, x, **kwargs):\n        return self.fn(self.norm(x), **kwargs)\n\nclass FeedForward(nn.Module):\n    def __init__(self, dim, hidden_dim, dropout = 0.):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(dim, hidden_dim),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, dim),\n            nn.Dropout(dropout)\n        )\n    def forward(self, x):\n        return self.net(x)\n\n\nclass Transformer(nn.Module):\n    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n        super().__init__()\n        self.layers = nn.ModuleList([])\n        local_attn_heads = 0\n        local_window_size = 256\n        causal = False\n        nb_features = None\n        generalized_attention = False\n        kernel_fn = nn.ReLU()\n        attn_dropout = 0.\n        no_projection = False\n        qkv_bias = True\n        attn_out_bias = True\n#           self.pos_emb = AxialRotaryEmbedding(dim_head)\n        for _ in range(depth):\n            self.layers.append(nn.ModuleList([\n                PreNorm(dim, SelfAttention(dim, causal = causal, heads = heads, dim_head = dim_head, local_heads = local_attn_heads, local_window_size = local_window_size, nb_features = nb_features, generalized_attention = generalized_attention, kernel_fn = kernel_fn, dropout = attn_dropout, no_projection = no_projection, qkv_bias = qkv_bias, attn_out_bias = attn_out_bias)),\n                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n            ]))\n    def forward(self, x, pos_emb):\n#         pos_emb = self.pos_emb(x[:, 1:])\n        for attn, ff in self.layers:\n            x = attn(x, pos_emb = pos_emb) + x\n            x = ff(x) + x\n        return x\n\nclass ViT(nn.Module):\n    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0., rotary_position_emb = True):\n        super().__init__()\n        image_height, image_width = pair(image_size)\n        patch_height, patch_width = pair(patch_size)\n        self.patch_size = patch_size\n\n        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n\n        num_patches = (image_height // patch_height) * (image_width // patch_width)\n        patch_dim = channels * patch_height * patch_width\n        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n\n        self.to_patch_embedding = nn.Sequential(\n        \n            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n            nn.Linear(patch_dim, dim)\n\n        )\n\n#         self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n        self.dropout = nn.Dropout(emb_dropout)\n\n        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n\n        self.pool = pool\n        self.to_latent = nn.Identity()\n\n        self.mlp_head = nn.Sequential(\n            nn.LayerNorm(dim),\n            nn.Linear(dim, num_classes)\n        )\n        max_seq_len = 1025\n        if rotary_position_emb:\n            self.layer_pos_emb = FixedPositionalEmbedding(dim_head, max_seq_len)\n\n    def forward(self, img):\n        b, _, h, w, p = *img.shape, self.patch_size\n        x = self.to_patch_embedding(img)\n#         b, n, _ = x.shape\n        n = x.shape[1]\n\n        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n        \n        x = torch.cat((cls_tokens, x), dim=1)\n#         x += self.pos_embedding[:, :(n + 1)]\n        x = self.dropout(x)\n#         fmap_dims = {'h': h // p, 'w': w // p}\n        layer_pos_emb = self.layer_pos_emb(x)\n        x = self.transformer(x, pos_emb = layer_pos_emb)\n\n        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n\n        x = self.to_latent(x)\n        return self.mlp_head(x)","metadata":{"id":"xqqgvetAX8Jh","execution":{"iopub.status.busy":"2021-07-29T03:51:27.187505Z","iopub.execute_input":"2021-07-29T03:51:27.187782Z","iopub.status.idle":"2021-07-29T03:51:27.210827Z","shell.execute_reply.started":"2021-07-29T03:51:27.187756Z","shell.execute_reply":"2021-07-29T03:51:27.209934Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\nmodel = ViT(\n    image_size = 32,\n    patch_size = 1,\n    num_classes = 10,             # number of stages\n    dim = 128,  # dimensions at each stage\n    depth = 4,              # transformer of depth 4 at each stage\n    heads = 4,      # heads at each stage\n    mlp_dim = 256,\n    dropout = 0.,\n    dim_head = 32\n)\n\n\nmodel.to(device)\nprint(summary(model, (3,32,32)))","metadata":{"id":"3xIkdVLXX8Jk","outputId":"8bf4f405-dc10-4bce-c8b7-ccbe52a1d1eb","execution":{"iopub.status.busy":"2021-07-29T03:51:27.212146Z","iopub.execute_input":"2021-07-29T03:51:27.212671Z","iopub.status.idle":"2021-07-29T03:51:32.128589Z","shell.execute_reply.started":"2021-07-29T03:51:27.212632Z","shell.execute_reply":"2021-07-29T03:51:32.127646Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n         Rearrange-1              [-1, 1024, 3]               0\n            Linear-2            [-1, 1024, 128]             512\n           Dropout-3            [-1, 1025, 128]               0\nFixedPositionalEmbedding-4             [-1, 1025, 32]               0\n         LayerNorm-5            [-1, 1025, 128]             256\n            Linear-6            [-1, 1025, 128]          16,512\n            Linear-7            [-1, 1025, 128]          16,512\n            Linear-8            [-1, 1025, 128]          16,512\n     FastAttention-9          [-1, 4, 1025, 32]               0\n           Linear-10            [-1, 1025, 128]          16,512\n          Dropout-11            [-1, 1025, 128]               0\n    SelfAttention-12            [-1, 1025, 128]               0\n          PreNorm-13            [-1, 1025, 128]               0\n        LayerNorm-14            [-1, 1025, 128]             256\n           Linear-15            [-1, 1025, 256]          33,024\n             GELU-16            [-1, 1025, 256]               0\n          Dropout-17            [-1, 1025, 256]               0\n           Linear-18            [-1, 1025, 128]          32,896\n          Dropout-19            [-1, 1025, 128]               0\n      FeedForward-20            [-1, 1025, 128]               0\n          PreNorm-21            [-1, 1025, 128]               0\n        LayerNorm-22            [-1, 1025, 128]             256\n           Linear-23            [-1, 1025, 128]          16,512\n           Linear-24            [-1, 1025, 128]          16,512\n           Linear-25            [-1, 1025, 128]          16,512\n    FastAttention-26          [-1, 4, 1025, 32]               0\n           Linear-27            [-1, 1025, 128]          16,512\n          Dropout-28            [-1, 1025, 128]               0\n    SelfAttention-29            [-1, 1025, 128]               0\n          PreNorm-30            [-1, 1025, 128]               0\n        LayerNorm-31            [-1, 1025, 128]             256\n           Linear-32            [-1, 1025, 256]          33,024\n             GELU-33            [-1, 1025, 256]               0\n          Dropout-34            [-1, 1025, 256]               0\n           Linear-35            [-1, 1025, 128]          32,896\n          Dropout-36            [-1, 1025, 128]               0\n      FeedForward-37            [-1, 1025, 128]               0\n          PreNorm-38            [-1, 1025, 128]               0\n        LayerNorm-39            [-1, 1025, 128]             256\n           Linear-40            [-1, 1025, 128]          16,512\n           Linear-41            [-1, 1025, 128]          16,512\n           Linear-42            [-1, 1025, 128]          16,512\n    FastAttention-43          [-1, 4, 1025, 32]               0\n           Linear-44            [-1, 1025, 128]          16,512\n          Dropout-45            [-1, 1025, 128]               0\n    SelfAttention-46            [-1, 1025, 128]               0\n          PreNorm-47            [-1, 1025, 128]               0\n        LayerNorm-48            [-1, 1025, 128]             256\n           Linear-49            [-1, 1025, 256]          33,024\n             GELU-50            [-1, 1025, 256]               0\n          Dropout-51            [-1, 1025, 256]               0\n           Linear-52            [-1, 1025, 128]          32,896\n          Dropout-53            [-1, 1025, 128]               0\n      FeedForward-54            [-1, 1025, 128]               0\n          PreNorm-55            [-1, 1025, 128]               0\n        LayerNorm-56            [-1, 1025, 128]             256\n           Linear-57            [-1, 1025, 128]          16,512\n           Linear-58            [-1, 1025, 128]          16,512\n           Linear-59            [-1, 1025, 128]          16,512\n    FastAttention-60          [-1, 4, 1025, 32]               0\n           Linear-61            [-1, 1025, 128]          16,512\n          Dropout-62            [-1, 1025, 128]               0\n    SelfAttention-63            [-1, 1025, 128]               0\n          PreNorm-64            [-1, 1025, 128]               0\n        LayerNorm-65            [-1, 1025, 128]             256\n           Linear-66            [-1, 1025, 256]          33,024\n             GELU-67            [-1, 1025, 256]               0\n          Dropout-68            [-1, 1025, 256]               0\n           Linear-69            [-1, 1025, 128]          32,896\n          Dropout-70            [-1, 1025, 128]               0\n      FeedForward-71            [-1, 1025, 128]               0\n          PreNorm-72            [-1, 1025, 128]               0\n      Transformer-73            [-1, 1025, 128]               0\n         Identity-74                  [-1, 128]               0\n        LayerNorm-75                  [-1, 128]             256\n           Linear-76                   [-1, 10]           1,290\n================================================================\nTotal params: 531,978\nTrainable params: 531,978\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 83.36\nParams size (MB): 2.03\nEstimated Total Size (MB): 85.40\n----------------------------------------------------------------\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\nscaler = torch.cuda.amp.GradScaler()\n# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\ntop1 = []\ntop5 = []\noptimizer = optim.AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\nfor epoch in range(40):  # loop over the dataset multiple times\n    t0 = time.time()\n    epoch_accuracy = 0\n    epoch_loss = 0\n    running_loss = 0.0\n\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data[0].to(device), data[1].to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        with torch.cuda.amp.autocast():\n            loss = criterion(outputs, labels)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        acc = (outputs.argmax(dim=1) == labels).float().mean()\n        epoch_accuracy += acc / len(trainloader)\n        epoch_loss += loss / len(trainloader)\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 200 == 199:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 2000))\n            running_loss = 0.0\n    correct = 0\n    total = 0\n    correct_1=0\n    correct_5=0\n    c = 0\n    with torch.no_grad():\n        for data in testloader:\n            images, labels = data[0].to(device), data[1].to(device)\n            outputs = model(images)\n#         outputs = net(images)\n\n            _, predicted = torch.max(outputs.data, 1)\n            res = accuracy(outputs, labels)\n            correct_1 += res[0][0].float()\n            correct_5 += res[1][0].float()\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            c += 1\n        \n    print(f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - Top 1: {correct_1/c} - Top 5: {correct_5/c} - Time: {time.time() - t0}\\n\")\n    top1.append(correct_1/c)\n    top5.append(correct_5/c)\n    if float(correct_1/c) >= float(max(top1)):\n        PATH = 'ViPRoPE.pth'\n        torch.save(model.state_dict(), PATH)\n        print(1)\nprint('Finished Training')","metadata":{"id":"6SF5eAgzX8Jl","outputId":"332abb30-6a69-457b-b77a-38b391df845c","execution":{"iopub.status.busy":"2021-07-29T03:51:32.131971Z","iopub.execute_input":"2021-07-29T03:51:32.132253Z","iopub.status.idle":"2021-07-29T06:02:03.556428Z","shell.execute_reply.started":"2021-07-29T03:51:32.132222Z","shell.execute_reply":"2021-07-29T06:02:03.554867Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[1,   200] loss: 0.186\nEpoch : 1 - loss : 1.8206 - acc: 0.3315 - Top 1: 41.08687210083008 - Top 5: 88.85613250732422 - Time: 233.35399413108826\n\n1\n[2,   200] loss: 0.159\nEpoch : 2 - loss : 1.5798 - acc: 0.4261 - Top 1: 46.31486511230469 - Top 5: 91.06721496582031 - Time: 233.5240466594696\n\n1\n[3,   200] loss: 0.148\nEpoch : 3 - loss : 1.4724 - acc: 0.4678 - Top 1: 49.81328201293945 - Top 5: 92.43318176269531 - Time: 233.6376657485962\n\n1\n[4,   200] loss: 0.141\nEpoch : 4 - loss : 1.4044 - acc: 0.4917 - Top 1: 48.211483001708984 - Top 5: 92.41351318359375 - Time: 233.70439553260803\n\n[5,   200] loss: 0.135\nEpoch : 5 - loss : 1.3427 - acc: 0.5159 - Top 1: 51.975242614746094 - Top 5: 93.63208770751953 - Time: 233.52467346191406\n\n1\n[6,   200] loss: 0.129\nEpoch : 6 - loss : 1.2891 - acc: 0.5345 - Top 1: 52.781063079833984 - Top 5: 94.38875579833984 - Time: 233.72939014434814\n\n1\n[7,   200] loss: 0.125\nEpoch : 7 - loss : 1.2438 - acc: 0.5510 - Top 1: 56.29914855957031 - Top 5: 94.86046600341797 - Time: 233.68013668060303\n\n1\n[8,   200] loss: 0.121\nEpoch : 8 - loss : 1.2059 - acc: 0.5676 - Top 1: 55.680030822753906 - Top 5: 94.7032470703125 - Time: 233.5072910785675\n\n[9,   200] loss: 0.116\nEpoch : 9 - loss : 1.1637 - acc: 0.5822 - Top 1: 56.25981903076172 - Top 5: 94.97837829589844 - Time: 233.581556558609\n\n[10,   200] loss: 0.113\nEpoch : 10 - loss : 1.1351 - acc: 0.5931 - Top 1: 57.32115173339844 - Top 5: 95.30268096923828 - Time: 233.55904984474182\n\n1\n[11,   200] loss: 0.109\nEpoch : 11 - loss : 1.0973 - acc: 0.6080 - Top 1: 57.959896087646484 - Top 5: 95.23388671875 - Time: 233.61475157737732\n\n1\n[12,   200] loss: 0.106\nEpoch : 12 - loss : 1.0666 - acc: 0.6177 - Top 1: 58.372642517089844 - Top 5: 95.44025421142578 - Time: 233.8132836818695\n\n1\n[13,   200] loss: 0.103\nEpoch : 13 - loss : 1.0363 - acc: 0.6289 - Top 1: 58.323509216308594 - Top 5: 95.29283905029297 - Time: 233.57185316085815\n\n[14,   200] loss: 0.100\nEpoch : 14 - loss : 1.0038 - acc: 0.6412 - Top 1: 59.04087829589844 - Top 5: 95.0962905883789 - Time: 233.74515008926392\n\n1\n[15,   200] loss: 0.098\nEpoch : 15 - loss : 0.9784 - acc: 0.6487 - Top 1: 59.325870513916016 - Top 5: 95.31249237060547 - Time: 233.86757349967957\n\n1\n[16,   200] loss: 0.094\nEpoch : 16 - loss : 0.9437 - acc: 0.6618 - Top 1: 59.93513870239258 - Top 5: 95.7645492553711 - Time: 233.6413860321045\n\n1\n[17,   200] loss: 0.092\nEpoch : 17 - loss : 0.9157 - acc: 0.6723 - Top 1: 60.22011947631836 - Top 5: 95.46971893310547 - Time: 233.7504222393036\n\n1\n[18,   200] loss: 0.087\nEpoch : 18 - loss : 0.8811 - acc: 0.6830 - Top 1: 60.7409553527832 - Top 5: 95.62696075439453 - Time: 233.84831309318542\n\n1\n[19,   200] loss: 0.084\nEpoch : 19 - loss : 0.8538 - acc: 0.6919 - Top 1: 60.38718032836914 - Top 5: 95.21424865722656 - Time: 233.79402256011963\n\n[20,   200] loss: 0.082\nEpoch : 20 - loss : 0.8264 - acc: 0.7035 - Top 1: 59.424129486083984 - Top 5: 95.43043518066406 - Time: 233.64995574951172\n\n[21,   200] loss: 0.078\nEpoch : 21 - loss : 0.7866 - acc: 0.7161 - Top 1: 59.75825500488281 - Top 5: 94.8407974243164 - Time: 233.690349817276\n\n[22,   200] loss: 0.076\nEpoch : 22 - loss : 0.7572 - acc: 0.7273 - Top 1: 60.26926040649414 - Top 5: 95.40095520019531 - Time: 233.82139945030212\n\n[23,   200] loss: 0.071\nEpoch : 23 - loss : 0.7243 - acc: 0.7387 - Top 1: 59.53224182128906 - Top 5: 95.46973419189453 - Time: 233.67554211616516\n\n[24,   200] loss: 0.068\nEpoch : 24 - loss : 0.6914 - acc: 0.7492 - Top 1: 60.347877502441406 - Top 5: 95.15526580810547 - Time: 233.67671632766724\n\n[25,   200] loss: 0.066\nEpoch : 25 - loss : 0.6680 - acc: 0.7585 - Top 1: 59.257076263427734 - Top 5: 95.00786590576172 - Time: 233.67319250106812\n\n[26,   200] loss: 0.062\nEpoch : 26 - loss : 0.6335 - acc: 0.7703 - Top 1: 59.64033126831055 - Top 5: 95.05699920654297 - Time: 233.60185432434082\n\n[27,   200] loss: 0.058\nEpoch : 27 - loss : 0.5935 - acc: 0.7867 - Top 1: 60.200477600097656 - Top 5: 95.07664489746094 - Time: 233.78096866607666\n\n[28,   200] loss: 0.056\nEpoch : 28 - loss : 0.5721 - acc: 0.7941 - Top 1: 59.09983444213867 - Top 5: 95.15526580810547 - Time: 233.63650608062744\n\n[29,   200] loss: 0.052\nEpoch : 29 - loss : 0.5341 - acc: 0.8068 - Top 1: 58.411956787109375 - Top 5: 94.8014907836914 - Time: 233.65734696388245\n\n[30,   200] loss: 0.049\nEpoch : 30 - loss : 0.5042 - acc: 0.8191 - Top 1: 59.72877502441406 - Top 5: 95.05699920654297 - Time: 233.52188801765442\n\n[31,   200] loss: 0.046\nEpoch : 31 - loss : 0.4772 - acc: 0.8275 - Top 1: 59.12931823730469 - Top 5: 94.82115173339844 - Time: 233.6838719844818\n\n[32,   200] loss: 0.044\nEpoch : 32 - loss : 0.4536 - acc: 0.8355 - Top 1: 59.3946418762207 - Top 5: 94.70321655273438 - Time: 233.63091158866882\n\n[33,   200] loss: 0.042\nEpoch : 33 - loss : 0.4298 - acc: 0.8446 - Top 1: 59.87618637084961 - Top 5: 94.66390991210938 - Time: 233.5639886856079\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-c0936f6a1604>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"plt.subplot(2, 1, 1)\nplt.plot(top1, '.-')\nplt.title('Accuracy')\nplt.ylabel('Top 1 accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(top5, '.-')\nplt.xlabel('epochs')\nplt.ylabel('Top 5 accuracy')\n\nplt.show()\n","metadata":{"id":"ejWrGxYZX8Jl","outputId":"c91a80fc-5362-4654-b9f5-de677bf14108","execution":{"iopub.status.busy":"2021-07-29T06:02:25.283981Z","iopub.execute_input":"2021-07-29T06:02:25.284305Z","iopub.status.idle":"2021-07-29T06:02:25.476641Z","shell.execute_reply.started":"2021-07-29T06:02:25.284273Z","shell.execute_reply":"2021-07-29T06:02:25.475884Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}